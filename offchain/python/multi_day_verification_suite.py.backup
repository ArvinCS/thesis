#!/usr/bin/env python3
"""
Multi-Day Verification Test Suite for Hierarchical Merkle Tree System

This comprehensive test suite simulates realistic multi-day verification scenarios
to demonstrate the effectiveness of the Pairs-first Huffman algorithm compared to
traditional multiproof approaches, including detailed gas cost analysis.

Key Features:
1. Realistic multi-day traffic simulation with property co-verification patterns
2. Comprehensive comparison between hierarchical and traditional approaches
3. Detailed gas cost analysis and optimization metrics
4. Performance visualization and reporting
5. Scalable testing across different document counts and time periods
"""

import json
import time
import random
import os
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from web3 import Web3
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Import existing components
from large_scale_generator import LargeScaleDocumentGenerator, RealisticTrafficGenerator
from jurisdiction_tree_manager import JurisdictionTreeManager
from benchmark_suite import ComprehensiveBenchmarkSuite
from traditional_multiproof_builder import TraditionalMerkleTreeBuilder
from traditional_single_proof_builder import TraditionalSingleProofMerkleTreeBuilder
from traditional_multiproof_with_huffman_builder import TraditionalMultiproofWithHuffmanBuilder
from report_organizer import save_organized_file

class MultiDayTrafficSimulator:
    """
    Simulates realistic multi-day verification traffic patterns with property co-verification.
    
    This simulator creates realistic patterns where:
    - Properties are frequently verified together (real estate portfolios, audits)
    - Traffic varies by day of week and time of day
    - Cross-province verifications follow realistic business patterns
    - Property co-verification frequencies are tracked for optimization
    """
    
    def __init__(self, documents, properties_by_province, seed=42):
        self.documents = documents
        self.properties_by_province = properties_by_province
        self.seed = seed
        random.seed(seed)
        
        # Traffic patterns based on real-world usage
        self.daily_patterns = {
            'Monday': {'base_multiplier': 1.2, 'peak_hours': [9, 10, 11, 14, 15]},
            'Tuesday': {'base_multiplier': 1.3, 'peak_hours': [9, 10, 11, 14, 15, 16]},
            'Wednesday': {'base_multiplier': 1.4, 'peak_hours': [9, 10, 11, 14, 15, 16]},
            'Thursday': {'base_multiplier': 1.3, 'peak_hours': [9, 10, 11, 14, 15, 16]},
            'Friday': {'base_multiplier': 1.1, 'peak_hours': [9, 10, 11, 14]},
            'Saturday': {'base_multiplier': 0.3, 'peak_hours': [10, 11]},
            'Sunday': {'base_multiplier': 0.1, 'peak_hours': []}
        }
        
        # Property co-verification patterns (simulating real estate portfolios)
        self.property_relationships = self._analyze_property_relationships()
        
    def _analyze_property_relationships(self):
        """Analyze property relationships for realistic co-verification patterns."""
        relationships = defaultdict(list)
        
        # Create realistic property relationships based on:
        # 1. Same province (administrative convenience)
        # 2. Property type (commercial portfolios, residential developments)
        # 3. Geographic proximity (simulated by property ID patterns)
        
        for province, properties in self.properties_by_province.items():
            # Group properties by type for portfolio relationships
            by_type = defaultdict(list)
            for prop in properties:
                prop_type = prop.get('type', 'residential')
                by_type[prop_type].append(prop)
            
            # Create relationships within property types (portfolios)
            for prop_type, props in by_type.items():
                if len(props) >= 2:
                    # Create clusters of 2-4 related properties
                    cluster_size = min(random.randint(2, 4), len(props))
                    clusters = [props[i:i+cluster_size] for i in range(0, len(props), cluster_size)]
                    
                    for cluster in clusters:
                        for i, prop1 in enumerate(cluster):
                            for prop2 in cluster[i+1:]:
                                relationships[prop1['full_id']].append(prop2['full_id'])
                                relationships[prop2['full_id']].append(prop1['full_id'])
        
        return relationships
    
    def generate_multi_day_traffic(self, num_days=7, base_events_per_day=200):
        """
        Generate realistic multi-day traffic with property co-verification patterns.
        
        Args:
            num_days: Number of days to simulate
            base_events_per_day: Base number of verification events per day
            
        Returns:
            Dictionary with daily traffic logs and co-verification statistics
        """
        print(f"Generating {num_days}-day traffic simulation with {base_events_per_day} base events/day...")
        
        all_traffic_logs = []
        daily_stats = {}
        co_verification_stats = defaultdict(int)
        
        start_date = datetime.now() - timedelta(days=num_days)
        
        for day_offset in range(num_days):
            current_date = start_date + timedelta(days=day_offset)
            day_name = current_date.strftime('%A')
            
            # Calculate events for this day based on patterns
            day_pattern = self.daily_patterns[day_name]
            daily_events = int(base_events_per_day * day_pattern['base_multiplier'])
            
            print(f"  Day {day_offset + 1} ({day_name}): {daily_events} events")
            
            # Generate events for this day
            day_traffic = self._generate_daily_traffic(daily_events, day_pattern)
            all_traffic_logs.extend(day_traffic)
            
            # Track co-verification statistics
            for event in day_traffic:
                for i, prop1 in enumerate(event):
                    for prop2 in event[i+1:]:
                        pair = tuple(sorted([prop1, prop2]))
                        co_verification_stats[pair] += 1
            
            # Daily statistics
            daily_stats[day_offset] = {
                'date': current_date.isoformat(),
                'day_name': day_name,
                'events': len(day_traffic),
                'total_properties': sum(len(event) for event in day_traffic),
                'avg_properties_per_event': np.mean([len(event) for event in day_traffic]) if day_traffic else 0,
                'cross_province_events': len([e for e in day_traffic if len(set(p.split('.')[0] for p in e)) > 1])
            }
        
        # Analyze co-verification patterns
        co_verification_analysis = self._analyze_co_verification_patterns(co_verification_stats)
        
        result = {
            'traffic_logs': all_traffic_logs,
            'daily_stats': daily_stats,
            'co_verification_stats': dict(co_verification_stats),
            'co_verification_analysis': co_verification_analysis,
            'total_events': len(all_traffic_logs),
            'total_days': num_days,
            'simulation_metadata': {
                'seed': self.seed,
                'base_events_per_day': base_events_per_day,
                'start_date': start_date.isoformat(),
                'end_date': (start_date + timedelta(days=num_days-1)).isoformat()
            }
        }
        
        print(f"Generated {len(all_traffic_logs)} total events over {num_days} days")
        print(f"Top co-verification pairs: {len([p for p, c in co_verification_stats.items() if c > 1])}")
        
        return result
    
    def _generate_daily_traffic(self, num_events, day_pattern):
        """Generate traffic events for a single day."""
        events = []
        province_names = list(self.properties_by_province.keys())
        
        for _ in range(num_events):
            # Determine event type based on realistic patterns
            event_type = self._choose_event_type()
            
            if event_type == 'single_property':
                # Single property verification
                province = random.choice(province_names)
                properties = self.properties_by_province[province]
                if properties:
                    prop = random.choice(properties)
                    events.append([prop['full_id']])
            
            elif event_type == 'property_portfolio':
                # Related properties (using our relationship analysis)
                # Pick a random property and include its related properties
                all_props = [p for props in self.properties_by_province.values() for p in props]
                if all_props:
                    base_prop = random.choice(all_props)
                    related_props = self.property_relationships.get(base_prop['full_id'], [])
                    
                    # Include base property and 1-3 related properties
                    portfolio_size = min(random.randint(2, 4), len(related_props) + 1)
                    event_props = [base_prop['full_id']]
                    
                    if related_props:
                        selected_related = random.sample(related_props, min(portfolio_size - 1, len(related_props)))
                        event_props.extend(selected_related)
                    
                    events.append(event_props)
            
            elif event_type == 'cross_province_audit':
                # Cross-province verification (audit scenario)
                num_provinces = random.randint(2, min(4, len(province_names)))
                selected_provinces = random.sample(province_names, num_provinces)
                event_props = []
                
                for province in selected_provinces:
                    properties = self.properties_by_province[province]
                    if properties:
                        num_props = random.randint(1, 3)
                        selected = random.sample(properties, min(num_props, len(properties)))
                        event_props.extend([p['full_id'] for p in selected])
                
                if event_props:
                    events.append(event_props)
            
            elif event_type == 'bulk_verification':
                # Large bulk verification (compliance check)
                num_provinces = random.randint(3, min(6, len(province_names)))
                selected_provinces = random.sample(province_names, num_provinces)
                event_props = []
                
                for province in selected_provinces:
                    properties = self.properties_by_province[province]
                    if properties:
                        num_props = random.randint(2, 5)
                        selected = random.sample(properties, min(num_props, len(properties)))
                        event_props.extend([p['full_id'] for p in selected])
                
                if event_props:
                    events.append(event_props)
        
        return events
    
    def _choose_event_type(self):
        """Choose event type based on realistic probabilities."""
        event_types = {
            'single_property': 0.4,      # 40% single property verifications
            'property_portfolio': 0.35,   # 35% related property verifications
            'cross_province_audit': 0.15, # 15% cross-province audits
            'bulk_verification': 0.1     # 10% large bulk verifications
        }
        
        rand = random.random()
        cumulative = 0
        
        for event_type, probability in event_types.items():
            cumulative += probability
            if rand <= cumulative:
                return event_type
        
        return 'single_property'
    
    def _analyze_co_verification_patterns(self, co_verification_stats):
        """Analyze property co-verification patterns for optimization insights."""
        if not co_verification_stats:
            return {}
        
        # Sort pairs by frequency
        sorted_pairs = sorted(co_verification_stats.items(), key=lambda x: x[1], reverse=True)
        
        # Analyze patterns
        total_pairs = len(co_verification_stats)
        frequent_pairs = len([p for p, c in co_verification_stats.items() if c > 1])
        
        # Calculate optimization potential
        optimization_potential = {
            'total_co_verification_pairs': total_pairs,
            'frequent_pairs': frequent_pairs,
            'optimization_ratio': frequent_pairs / total_pairs if total_pairs > 0 else 0,
            'top_10_pairs': sorted_pairs[:10],
            'max_co_verification_frequency': max(co_verification_stats.values()) if co_verification_stats else 0,
            'avg_co_verification_frequency': np.mean(list(co_verification_stats.values())) if co_verification_stats else 0
        }
        
        return optimization_potential

class MultiDayVerificationSuite:
    """
    Comprehensive test suite for multi-day verification scenarios.
    
    This suite compares:
    1. Hierarchical approach with Pairs-first Huffman optimization
    2. Traditional multiproof approach
    3. Traditional single proof approach
    
    And measures:
    - Proof sizes
    - Gas costs
    - Verification times
    - Optimization effectiveness
    """
    
    def __init__(self, web3_instance=None):
        self.web3 = web3_instance
        self.performance_data = {}
        self.gas_analysis = {}
        
        # Setup contracts if Web3 available
        if self.web3:
            self._setup_contracts()
    
    def _setup_contracts(self):
        """Setup smart contracts for gas cost analysis."""
        try:
            # Hierarchical contract
            hierarchical_artifact_path = '../../artifacts/contracts/StatelessHierarchicalVerifier.sol/StatelessHierarchicalVerifier.json'
            with open(hierarchical_artifact_path, 'r') as f:
                hierarchical_artifact = json.load(f)
            
            hierarchical_address = hierarchical_artifact['networks']['31337']['address']
            self.hierarchical_contract = self.web3.eth.contract(
                address=hierarchical_address,
                abi=hierarchical_artifact['abi']
            )
            
            # Traditional multiproof contract
            traditional_artifact_path = '../../artifacts/contracts/MerkleVerifier.sol/MerkleVerifier.json'
            with open(traditional_artifact_path, 'r') as f:
                traditional_artifact = json.load(f)
            
            traditional_address = traditional_artifact['networks']['31337']['address']
            self.traditional_contract = self.web3.eth.contract(
                address=traditional_address,
                abi=traditional_artifact['abi']
            )
            
            # Single proof contract
            single_proof_artifact_path = '../../artifacts/contracts/SingleProofMerkleVerifier.sol/SingleProofMerkleVerifier.json'
            with open(single_proof_artifact_path, 'r') as f:
                single_proof_artifact = json.load(f)
            
            single_proof_address = single_proof_artifact['networks']['31337']['address']
            self.single_proof_contract = self.web3.eth.contract(
                address=single_proof_address,
                abi=single_proof_artifact['abi']
            )
            
            print("✅ All contracts loaded successfully for gas analysis")
            
        except Exception as e:
            print(f"⚠️  Contract setup failed: {e}")
            self.hierarchical_contract = None
            self.traditional_contract = None
            self.single_proof_contract = None
    
    def run_comprehensive_multi_day_test(self, document_count=3000, num_days=7, base_events_per_day=300, force_onchain_verification=False, sparse_verification=False, verification_sampling_rate=1.0):
        """
        Run comprehensive multi-day verification test suite.
        
        Args:
            document_count: Number of documents to generate
            num_days: Number of days to simulate
            base_events_per_day: Base number of verification events per day
            force_onchain_verification: If True, perform actual on-chain transactions
            sparse_verification: If True, use sparse verification with sampling
            verification_sampling_rate: Fraction of documents to include in each verification (0.0-1.0)
            
        Returns:
            Comprehensive test results with performance analysis
        """
        # Increase recursion limit for large-scale tree building
        # TODO: check this recursion limit
        import sys
        original_recursion_limit = sys.getrecursionlimit()
        if document_count > 10000:
            new_limit = max(5000, original_recursion_limit)
            sys.setrecursionlimit(new_limit)
            print(f"Increased recursion limit from {original_recursion_limit} to {new_limit} for large-scale processing")
        
        try:
            print(f"{'='*80}")
            print(f"COMPREHENSIVE MULTI-DAY VERIFICATION TEST SUITE")
            print(f"{'='*80}")
            print(f"Configuration:")
            print(f"  Documents: {document_count}")
            print(f"  Days: {num_days}")
            print(f"  Base events/day: {base_events_per_day}")
            print(f"  Total expected events: {num_days * base_events_per_day}")
            print(f"  Sparse Verification: {'ENABLED' if sparse_verification else 'DISABLED'}")
            if sparse_verification:
                print(f"  Verification Sampling Rate: {verification_sampling_rate*100:.1f}%")
            print(f"  On-chain Verification: {'ENABLED' if force_onchain_verification else 'ESTIMATE ONLY'}")
            
            if force_onchain_verification and not self.web3:
                raise Exception("On-chain verification requested but Web3 connection not available")
        
            self.force_onchain_verification = force_onchain_verification
            self.sparse_verification = sparse_verification
            self.verification_sampling_rate = verification_sampling_rate
            
            overall_start_time = time.time()
            
            # Step 1: Generate test data
            print(f"\n--- STEP 1: GENERATING TEST DATA ---")
            documents, traffic_data, properties_by_province = self._generate_test_data(
                document_count, num_days, base_events_per_day
            )
            
            # Apply sparse sampling if enabled
            if sparse_verification:
                print(f"\n--- APPLYING SPARSE VERIFICATION SAMPLING ---")
                original_traffic_logs = traffic_data['traffic_logs']
                original_count = sum(len(event) for event in original_traffic_logs)
                sampled_traffic_logs = self._apply_sparse_sampling(original_traffic_logs)
                sampled_count = sum(len(event) for event in sampled_traffic_logs)
                print(f"  Reduced from {original_count} to {sampled_count} properties ({(1-sampled_count/original_count)*100:.1f}% reduction)")
                
                # Create updated traffic data structure with sampled logs
                traffic_data = traffic_data.copy()  # Copy original structure
                traffic_data['traffic_logs'] = sampled_traffic_logs
                traffic_data['total_events'] = sampled_count
            
            # Step 2: Build all tree systems
            print(f"\n--- STEP 2: BUILDING TREE SYSTEMS ---")
            tree_systems = self._build_all_tree_systems(documents, traffic_data)
            
            # Step 3: Run multi-day verification tests
            print(f"\n--- STEP 3: RUNNING MULTI-DAY VERIFICATION TESTS ---")
            verification_results = self._run_multi_day_verification_tests(
                tree_systems, traffic_data, num_days
            )
            
            # Step 4: Analyze optimization effectiveness
            print(f"\n--- STEP 4: ANALYZING OPTIMIZATION EFFECTIVENESS ---")
            optimization_analysis = self._analyze_optimization_effectiveness(verification_results)
            
            # Step 5: Generate comprehensive report
            print(f"\n--- STEP 5: GENERATING COMPREHENSIVE REPORT ---")
            final_report = self._generate_comprehensive_report(
                documents, traffic_data, tree_systems, verification_results, 
                optimization_analysis, overall_start_time
            )
            
            total_time = time.time() - overall_start_time
            print(f"\n{'='*80}")
            print(f"COMPREHENSIVE TEST COMPLETED IN {total_time:.2f}s")
            print(f"{'='*80}")
            
            return final_report
        
        finally:
            # Restore original recursion limit
            if document_count > 10000:
                sys.setrecursionlimit(original_recursion_limit)
                print(f"Restored recursion limit to {original_recursion_limit}")
    
    def _generate_test_data(self, document_count, num_days, base_events_per_day):
        """Generate test data with multi-day traffic simulation."""
        # Generate documents
        doc_generator = LargeScaleDocumentGenerator(target_document_count=document_count, seed=42)
        documents = doc_generator.generate_documents()
        
        # Generate multi-day traffic
        traffic_simulator = MultiDayTrafficSimulator(documents, doc_generator.properties_by_province, seed=42)
        traffic_data = traffic_simulator.generate_multi_day_traffic(num_days, base_events_per_day)
        
        return documents, traffic_data, doc_generator.properties_by_province
    
    def _build_all_tree_systems(self, documents, traffic_data):
        """Build all tree systems for comparison."""
        traffic_logs = traffic_data['traffic_logs']
        
        print("Building Hierarchical System with Pairs-first Huffman optimization...")
        hierarchical_start = time.time()
        jurisdiction_manager = JurisdictionTreeManager(documents, traffic_logs)
        jurisdiction_root = jurisdiction_manager.build_all_trees()
        hierarchical_build_time = time.time() - hierarchical_start
        
        # Update the smart contract with the new jurisdiction root if available
        if hasattr(self, 'hierarchical_contract') and self.hierarchical_contract and hasattr(self, 'web3') and self.web3:
            try:
                print("🔄 Updating smart contract jurisdiction root...")
                if jurisdiction_root.startswith('0x'):
                    root_bytes = bytes.fromhex(jurisdiction_root[2:])
                else:
                    root_bytes = bytes.fromhex(jurisdiction_root)
                
                accounts = self.web3.eth.accounts
                tx_hash = self.hierarchical_contract.functions.updateJurisdictionRoot(root_bytes).transact({'from': accounts[0]})
                self.web3.eth.wait_for_transaction_receipt(tx_hash)
                print(f"✅ Jurisdiction root updated in smart contract: {jurisdiction_root[:16]}...")
            except Exception as e:
                print(f"⚠️  Failed to update jurisdiction root in smart contract: {e}")
                print("   Hierarchical verification may fail")
        
        print("Building Traditional Multiproof System...")
        traditional_start = time.time()
        traditional_multiproof_builder = TraditionalMerkleTreeBuilder(documents)
        traditional_root = traditional_multiproof_builder.build()
        traditional_build_time = time.time() - traditional_start
        
        print("Building Traditional Single Proof System...")
        single_proof_start = time.time()
        traditional_single_proof_builder = TraditionalSingleProofMerkleTreeBuilder(documents)
        single_proof_root = traditional_single_proof_builder.build()
        single_proof_build_time = time.time() - single_proof_start
        
        print("Building Traditional + Huffman System...")
        huffman_start = time.time()
        traditional_huffman_builder = TraditionalMultiproofWithHuffmanBuilder(documents)
        huffman_root = traditional_huffman_builder.build()
        huffman_build_time = time.time() - huffman_start
        
        tree_systems = {
            'hierarchical': {
                'manager': jurisdiction_manager,
                'root': jurisdiction_root,
                'build_time': hierarchical_build_time,
                'type': 'Hierarchical with Pairs-first Huffman'
            },
            'traditional_multiproof': {
                'builder': traditional_multiproof_builder,
                'root': traditional_root,
                'build_time': traditional_build_time,
                'type': 'Traditional Multiproof'
            },
            'traditional_single_proof': {
                'builder': traditional_single_proof_builder,
                'root': single_proof_root,
                'build_time': single_proof_build_time,
                'type': 'Traditional Single Proof'
            },
            'traditional_huffman': {
                'builder': traditional_huffman_builder,
                'root': huffman_root,
                'build_time': huffman_build_time,
                'type': 'Traditional + Huffman'
            }
        }
        
        print(f"Tree building completed:")
        print(f"  Hierarchical: {hierarchical_build_time:.3f}s")
        print(f"  Traditional Multiproof: {traditional_build_time:.3f}s")
        print(f"  Traditional Single Proof: {single_proof_build_time:.3f}s")
        print(f"  Traditional + Huffman: {huffman_build_time:.3f}s")
        
        return tree_systems
    
    def _run_multi_day_verification_tests(self, tree_systems, traffic_data, num_days):
        """Run verification tests across multiple days."""
        traffic_logs = traffic_data['traffic_logs']
        daily_stats = traffic_data['daily_stats']
        
        # Group traffic logs by day
        events_per_day = len(traffic_logs) // num_days
        daily_traffic = [traffic_logs[i:i+events_per_day] for i in range(0, len(traffic_logs), events_per_day)]
        
        all_results = []
        
        for day_idx, day_traffic in enumerate(daily_traffic):
            print(f"\nTesting Day {day_idx + 1} ({len(day_traffic)} events)...")
            
            day_results = self._test_single_day(
                tree_systems, day_traffic, day_idx, daily_stats.get(day_idx, {})
            )
            
            all_results.extend(day_results)
        
        return all_results
    
    def _test_single_day(self, tree_systems, day_traffic, day_idx, day_stats):
        """Test verification for a single day."""
        results = []
        
        # Sample events for testing (to avoid overwhelming the system)
        test_events = random.sample(day_traffic, min(50, len(day_traffic)))
        
        for event_idx, event in enumerate(test_events):
            if len(event) == 0:
                continue
            
            # Test each approach
            for approach_name, system in tree_systems.items():
                try:
                    result = self._test_single_verification_event(
                        approach_name, system, event, day_idx, event_idx
                    )
                    results.append(result)
                except Exception as e:
                    print(f"    Error testing {approach_name}: {e}")
                    results.append({
                        'approach': approach_name,
                        'day': day_idx,
                        'event': event_idx,
                        'error': str(e)
                    })
        
        return results
    
    def _test_single_verification_event(self, approach_name, system, event, day_idx, event_idx):
        """Test a single verification event with one approach."""
        start_time = time.time()
        
        if approach_name == 'hierarchical':
            # Hierarchical approach
            verification_request = self._convert_event_to_verification_request(event)
            proof_package = system['manager'].verify_cross_province_batch(verification_request)
            
            # Verify locally
            is_valid, reason = system['manager'].verify_proof_package_locally(proof_package)
            
            # Calculate proof size
            proof_size = self._calculate_hierarchical_proof_size(proof_package)
            
            # Estimate gas and optionally execute on-chain if contract available
            estimated_gas = None
            actual_gas_used = None
            if self.hierarchical_contract and is_valid:
                try:
                    estimated_gas, actual_gas_used = self._estimate_hierarchical_gas(proof_package)
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'day': day_idx,
                'event': event_idx,
                'properties_count': len(event),
                'provinces_count': len(set(p.split('.')[0] for p in event)),
                'verification_time': verification_time,
                'proof_size_bytes': proof_size,
                'estimated_gas': estimated_gas,
                'actual_gas_used': actual_gas_used,
                'local_verification_passed': is_valid,
                'reason': reason,
                'cross_province': len(set(p.split('.')[0] for p in event)) > 1
            }
        
        elif approach_name == 'traditional_multiproof':
            # Traditional multiproof approach
            # Collect all document hashes for the event
            all_doc_hashes = []
            for prop_id in event:
                # Find documents for this property
                for doc in system['builder'].all_documents:
                    if doc.full_id == prop_id:
                        all_doc_hashes.append(doc.hash_hex)
            
            # Deduplicate to ensure unique leaves
            all_doc_hashes = list(dict.fromkeys(all_doc_hashes))
            
            if not all_doc_hashes:
                return {
                    'approach': approach_name,
                    'day': day_idx,
                    'event': event_idx,
                    'error': 'No documents found for event'
                }
            
            # Generate multiproof
            proof, flags = system['builder'].generate_proof_for_documents(all_doc_hashes)
            proof_size = len(proof) * 32 + len(flags) + len(all_doc_hashes) * 32
            
            # Estimate gas and optionally execute on-chain if contract available
            estimated_gas = None
            actual_gas_used = None
            if self.traditional_contract:
                try:
                    proof_bytes = [bytes.fromhex(p) for p in proof]
                    # Use the same sorted order as generator
                    leaves_sorted = sorted(all_doc_hashes)
                    leaves_bytes = [bytes.fromhex(l) for l in leaves_sorted]
                    
                    if self.force_onchain_verification:
                        # Perform actual on-chain verification
                        print(f"      Executing on-chain traditional multiproof verification...")
                        
                        # First estimate gas
                        estimated_gas = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).estimate_gas()
                        
                        # Execute actual transaction
                        tx_hash = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).transact()
                        
                        # Wait for transaction receipt and get actual gas used
                        receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
                        actual_gas_used = receipt.gasUsed
                        
                        print(f"      ✅ On-chain verification successful - Gas used: {actual_gas_used}")
                        
                    else:
                        # Just estimate gas
                        estimated_gas = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).estimate_gas()
                        
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'day': day_idx,
                'event': event_idx,
                'properties_count': len(event),
                'provinces_count': len(set(p.split('.')[0] for p in event)),
                'verification_time': verification_time,
                'proof_size_bytes': proof_size,
                'estimated_gas': estimated_gas,
                'actual_gas_used': actual_gas_used,
                'local_verification_passed': True,
                'cross_province': len(set(p.split('.')[0] for p in event)) > 1
            }
        
        elif approach_name == 'traditional_single_proof':
            # Traditional single proof approach
            all_doc_hashes = []
            for prop_id in event:
                for doc in system['builder'].all_documents:
                    if doc.full_id == prop_id:
                        all_doc_hashes.append(doc.hash_hex)
            
            # Deduplicate
            all_doc_hashes = list(dict.fromkeys(all_doc_hashes))
            
            if not all_doc_hashes:
                return {
                    'approach': approach_name,
                    'day': day_idx,
                    'event': event_idx,
                    'error': 'No documents found for event'
                }
            
            # Generate individual proofs
            individual_proofs = system['builder'].generate_single_proofs_for_documents(all_doc_hashes)
            total_proof_size = sum(len(proof['proof']) * 32 + 32 for proof in individual_proofs)
            
            # Estimate gas if contract available
            estimated_gas = None
            if self.single_proof_contract:
                try:
                    total_gas = 0
                    for proof_data in individual_proofs:
                        proof_bytes = [bytes.fromhex(p) for p in proof_data['proof']]
                        leaf_bytes = bytes.fromhex(proof_data.get('document_hash') or proof_data.get('leaf'))
                        gas_estimate = self.single_proof_contract.functions.verifySingle(
                            proof_bytes, leaf_bytes
                        ).estimate_gas()
                        total_gas += gas_estimate
                    estimated_gas = total_gas
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'day': day_idx,
                'event': event_idx,
                'properties_count': len(event),
                'provinces_count': len(set(p.split('.')[0] for p in event)),
                'verification_time': verification_time,
                'proof_size_bytes': total_proof_size,
                'estimated_gas': estimated_gas,
                'local_verification_passed': True,
                'cross_province': len(set(p.split('.')[0] for p in event)) > 1,
                'individual_proofs_count': len(individual_proofs)
            }
    
    def _convert_event_to_verification_request(self, event):
        """Convert a traffic event to hierarchical verification request format."""
        verification_request = defaultdict(list)
        
        for prop_id in event:
            if '.' in prop_id:
                province, property_id = prop_id.split('.', 1)
                verification_request[province].append(prop_id)
        
        return dict(verification_request)
    
    def _calculate_hierarchical_proof_size(self, proof_package):
        """Calculate total proof size for hierarchical approach."""
        total_size = 0
        
        # Province proofs
        for province_proof in proof_package['province_proofs'].values():
            total_size += len(province_proof['proof']) * 32  # 32 bytes per hash
            total_size += len(province_proof['flags'])  # 1 byte per flag
            total_size += len(province_proof['document_hashes']) * 32
        
        # Jurisdiction proof
        total_size += len(proof_package['jurisdiction_proof']['proof']) * 32
        total_size += len(proof_package['jurisdiction_proof']['flags'])
        
        return total_size
    
    def _estimate_hierarchical_gas(self, proof_package):
        """Estimate gas cost for hierarchical verification and optionally execute on-chain."""
        if not self.hierarchical_contract:
            return None, None
        
        # Prepare data for on-chain verification (match contract ABI)
        claimed_province_roots = []
        province_proofs = []
        province_flags = []
        province_leaves_arrays = []
        provinces_involved = proof_package['jurisdiction_proof']['provinces_involved']
        
        for province in provinces_involved:
            province_proof_data = proof_package['province_proofs'][province]
            proof_bytes = [bytes.fromhex(p) for p in province_proof_data['proof']]
            leaves_bytes = [bytes.fromhex(l) for l in province_proof_data['document_hashes']]
            
            # Province root must be passed first per ABI
            claimed_province_roots.append(bytes.fromhex(province_proof_data['expected_root']))
            province_proofs.append(proof_bytes)
            province_flags.append(province_proof_data['flags'])
            province_leaves_arrays.append(leaves_bytes)
        
        jurisdiction_proof_bytes = [bytes.fromhex(p) for p in proof_package['jurisdiction_proof']['proof']]
        jurisdiction_flags = proof_package['jurisdiction_proof']['flags']
        
        if self.force_onchain_verification:
            # Perform actual on-chain verification
            print(f"      Executing on-chain hierarchical verification...")
            
            # First estimate gas
            estimated_gas = self.hierarchical_contract.functions.verifyHierarchicalBatch(
                claimed_province_roots,          # bytes32[] claimedProvinceRoots
                jurisdiction_proof_bytes,        # bytes32[] jurisdictionProof
                jurisdiction_flags,              # bool[] jurisdictionFlags
                province_proofs,                 # bytes32[][] provinceProofs
                province_flags,                  # bool[][] provinceFlags
                province_leaves_arrays           # bytes32[][] provinceLeavesArrays
            ).estimate_gas()
            
            # Execute actual transaction
            tx_hash = self.hierarchical_contract.functions.verifyHierarchicalBatch(
                claimed_province_roots,
                jurisdiction_proof_bytes,
                jurisdiction_flags,
                province_proofs,
                province_flags,
                province_leaves_arrays
            ).transact()
            
            # Wait for transaction receipt and get actual gas used
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            actual_gas_used = receipt.gasUsed
            
            print(f"      ✅ On-chain verification successful - Gas used: {actual_gas_used}")
            
            return estimated_gas, actual_gas_used
            
        else:
            # Just estimate gas
            estimated_gas = self.hierarchical_contract.functions.verifyHierarchicalBatch(
                claimed_province_roots,          # bytes32[] claimedProvinceRoots
                jurisdiction_proof_bytes,        # bytes32[] jurisdictionProof
                jurisdiction_flags,              # bool[] jurisdictionFlags
                province_proofs,                 # bytes32[][] provinceProofs
                province_flags,                  # bool[][] provinceFlags
                province_leaves_arrays           # bytes32[][] provinceLeavesArrays
            ).estimate_gas()
            
            return estimated_gas, None
    
    def _analyze_optimization_effectiveness(self, verification_results):
        """Analyze the effectiveness of the Pairs-first Huffman optimization."""
        print("Analyzing optimization effectiveness...")
        
        # Group results by approach
        by_approach = defaultdict(list)
        for result in verification_results:
            if 'error' not in result:
                by_approach[result['approach']].append(result)
        
        analysis = {}
        
        for approach, results in by_approach.items():
            if not results:
                continue
            
            # Calculate statistics
            proof_sizes = [r['proof_size_bytes'] for r in results if 'proof_size_bytes' in r]
            verification_times = [r['verification_time'] for r in results if 'verification_time' in r]
            gas_estimates = [r['estimated_gas'] for r in results if 'estimated_gas' in r and isinstance(r['estimated_gas'], int)]
            actual_gas_usage = [r['actual_gas_used'] for r in results if 'actual_gas_used' in r and r['actual_gas_used'] is not None and isinstance(r['actual_gas_used'], int)]
            
            analysis[approach] = {
                'total_tests': len(results),
                'avg_proof_size_bytes': np.mean(proof_sizes) if proof_sizes else 0,
                'median_proof_size_bytes': np.median(proof_sizes) if proof_sizes else 0,
                'avg_verification_time': np.mean(verification_times) if verification_times else 0,
                'avg_gas_estimate': np.mean(gas_estimates) if gas_estimates else 0,
                'avg_actual_gas_used': np.mean(actual_gas_usage) if actual_gas_usage else 0,
                'total_estimated_tests': len(gas_estimates),
                'total_actual_tests': len(actual_gas_usage),
                'cross_province_tests': len([r for r in results if r.get('cross_province', False)]),
                'single_province_tests': len([r for r in results if not r.get('cross_province', False)])
            }
        
        # Calculate optimization ratios
        if 'hierarchical' in analysis and 'traditional_multiproof' in analysis:
            hierarchical = analysis['hierarchical']
            traditional = analysis['traditional_multiproof']
            
            # Basic optimization metrics
            analysis['optimization_ratios'] = {
                'proof_size_reduction': (traditional['avg_proof_size_bytes'] - hierarchical['avg_proof_size_bytes']) / traditional['avg_proof_size_bytes'] * 100 if traditional['avg_proof_size_bytes'] > 0 else 0,
                'gas_reduction_estimated': (traditional['avg_gas_estimate'] - hierarchical['avg_gas_estimate']) / traditional['avg_gas_estimate'] * 100 if traditional['avg_gas_estimate'] > 0 else 0,
                'gas_reduction_actual': (traditional['avg_actual_gas_used'] - hierarchical['avg_actual_gas_used']) / traditional['avg_actual_gas_used'] * 100 if traditional['avg_actual_gas_used'] > 0 else 0,
                'time_improvement': (traditional['avg_verification_time'] - hierarchical['avg_verification_time']) / traditional['avg_verification_time'] * 100 if traditional['avg_verification_time'] > 0 else 0,
                # Keep legacy field for backward compatibility
                'gas_reduction': (traditional['avg_gas_estimate'] - hierarchical['avg_gas_estimate']) / traditional['avg_gas_estimate'] * 100 if traditional['avg_gas_estimate'] > 0 else 0
            }
            
            # Estimation vs Actual analysis
            analysis['estimation_accuracy'] = {}
            
            # Hierarchical approach accuracy
            if hierarchical['avg_gas_estimate'] > 0 and hierarchical['avg_actual_gas_used'] > 0:
                hier_estimation_error = abs(hierarchical['avg_actual_gas_used'] - hierarchical['avg_gas_estimate']) / hierarchical['avg_gas_estimate'] * 100
                analysis['estimation_accuracy']['hierarchical'] = {
                    'estimated_gas': hierarchical['avg_gas_estimate'],
                    'actual_gas': hierarchical['avg_actual_gas_used'],
                    'estimation_error_percent': hier_estimation_error,
                    'estimation_direction': 'overestimate' if hierarchical['avg_gas_estimate'] > hierarchical['avg_actual_gas_used'] else 'underestimate'
                }
            
            # Traditional approach accuracy
            if traditional['avg_gas_estimate'] > 0 and traditional['avg_actual_gas_used'] > 0:
                trad_estimation_error = abs(traditional['avg_actual_gas_used'] - traditional['avg_gas_estimate']) / traditional['avg_gas_estimate'] * 100
                analysis['estimation_accuracy']['traditional'] = {
                    'estimated_gas': traditional['avg_gas_estimate'],
                    'actual_gas': traditional['avg_actual_gas_used'],
                    'estimation_error_percent': trad_estimation_error,
                    'estimation_direction': 'overestimate' if traditional['avg_gas_estimate'] > traditional['avg_actual_gas_used'] else 'underestimate'
                }
            
            # Overall estimation vs actual comparison
            if (hierarchical['avg_gas_estimate'] > 0 and hierarchical['avg_actual_gas_used'] > 0 and 
                traditional['avg_gas_estimate'] > 0 and traditional['avg_actual_gas_used'] > 0):
                
                estimated_reduction = analysis['optimization_ratios']['gas_reduction_estimated']
                actual_reduction = analysis['optimization_ratios']['gas_reduction_actual']
                
                analysis['estimation_accuracy']['comparison'] = {
                    'estimated_gas_reduction': estimated_reduction,
                    'actual_gas_reduction': actual_reduction,
                    'reduction_difference': abs(actual_reduction - estimated_reduction),
                    'accuracy_impact': 'estimation_worse' if estimated_reduction < actual_reduction else 'estimation_better'
                }
        
        return analysis
    
    def _generate_comprehensive_report(self, documents, traffic_data, tree_systems, 
                                     verification_results, optimization_analysis, start_time):
        """Generate comprehensive test report."""
        total_time = time.time() - start_time
        
        report = {
            'test_metadata': {
                'total_duration_seconds': total_time,
                'document_count': len(documents),
                'traffic_events': len(traffic_data['traffic_logs']),
                'simulation_days': traffic_data['total_days'],
                'timestamp': datetime.now().isoformat()
            },
            'traffic_analysis': {
                'daily_stats': traffic_data['daily_stats'],
                'co_verification_analysis': traffic_data['co_verification_analysis'],
                'total_co_verification_pairs': len(traffic_data['co_verification_stats'])
            },
            'tree_systems': {
                name: {
                    'type': system['type'],
                    'build_time': system['build_time'],
                    'root': system['root'][:16] + '...' if system['root'] else None
                }
                for name, system in tree_systems.items()
            },
            'verification_results': verification_results,
            'optimization_analysis': optimization_analysis,
            'performance_summary': self._generate_performance_summary(verification_results, optimization_analysis)
        }
        
        # Save report
        report_filename = f'multi_day_verification_report_{len(documents)}docs_{int(time.time())}.json'
        report_file = save_organized_file(report, report_filename, "verification_reports")
        
        print(f"Comprehensive report saved to: {report_file}")
        
        return report
    
    def _generate_performance_summary(self, verification_results, optimization_analysis):
        """Generate performance summary for the report."""
        summary = {
            'total_verification_tests': len(verification_results),
            'successful_tests': len([r for r in verification_results if 'error' not in r]),
            'failed_tests': len([r for r in verification_results if 'error' in r])
        }
        
        if 'optimization_ratios' in optimization_analysis:
            ratios = optimization_analysis['optimization_ratios']
            summary['optimization_benefits'] = {
                'proof_size_reduction_percent': ratios['proof_size_reduction'],
                'gas_reduction_percent': ratios['gas_reduction'],
                'time_improvement_percent': ratios['time_improvement']
            }
        
        return summary
    
    def _apply_sparse_sampling(self, traffic_logs):
        """Apply sparse sampling to traffic logs for large-scale testing."""
        if not hasattr(self, 'verification_sampling_rate'):
            return traffic_logs
        
        sampled_logs = []
        for event in traffic_logs:
            # Randomly sample properties within each event
            if len(event) > 1:
                sample_size = max(1, int(len(event) * self.verification_sampling_rate))
                sampled_event = random.sample(event, sample_size)
                sampled_logs.append(sampled_event)
            else:
                sampled_logs.append(event)
        
        return sampled_logs

    def run_cross_province_focused_test(self, documents, properties_by_province, traffic_logs, force_onchain_verification=False):
        """
        Run verification test focused on cross-province scenarios.
        
        Args:
            documents: Generated documents
            properties_by_province: Properties organized by province
            traffic_logs: Pre-generated traffic logs (should be 80% 4+ cross-province)
            force_onchain_verification: Whether to execute on-chain transactions
            
        Returns:
            Cross-province focused test results
        """
        print(f"{'='*60}")
        print(f"CROSS-PROVINCE FOCUSED VERIFICATION TEST")
        print(f"{'='*60}")
        
        self.force_onchain_verification = force_onchain_verification
        
        start_time = time.time()
        
        # Analyze traffic patterns first
        cross_province_stats = self._analyze_cross_province_traffic(traffic_logs)
        print(f"Traffic Analysis:")
        print(f"  Total events: {cross_province_stats['total_events']}")
        print(f"  4+ province events: {cross_province_stats['cross_province_4plus']} ({cross_province_stats['cross_province_4plus_percentage']:.1f}%)")
        
        # Build tree systems
        print(f"\nBuilding tree systems...")
        tree_systems = self._build_cross_province_tree_systems(documents, traffic_logs)
        
        # Run verification tests focused on 4+ province scenarios
        print(f"\nRunning cross-province verification tests...")
        verification_results = self._run_cross_province_verification_tests(tree_systems, traffic_logs)
        
        # Analyze results with focus on 4+ province scenarios
        print(f"\nAnalyzing cross-province performance...")
        cross_province_analysis = self._analyze_cross_province_performance(verification_results)
        
        total_time = time.time() - start_time
        
        results = {
            'test_metadata': {
                'test_type': 'cross_province_focused',
                'total_duration_seconds': total_time,
                'document_count': len(documents),
                'traffic_events': len(traffic_logs),
                'timestamp': datetime.now().isoformat(),
                'force_onchain_verification': force_onchain_verification
            },
            'cross_province_traffic_stats': cross_province_stats,
            'tree_systems': {
                name: {
                    'type': system['type'],
                    'build_time': system['build_time'],
                    'root': system['root'][:16] + '...' if system['root'] else None
                }
                for name, system in tree_systems.items()
            },
            'verification_results': verification_results,
            'cross_province_analysis': cross_province_analysis,
            'performance_summary': {
                'hierarchical_wins_4plus_provinces': cross_province_analysis.get('hierarchical_wins_4plus', 0),
                'traditional_wins_4plus_provinces': cross_province_analysis.get('traditional_wins_4plus', 0),
                'hierarchical_win_rate_4plus': cross_province_analysis.get('hierarchical_win_rate_4plus', 0)
            }
        }
        
        print(f"\n✅ Cross-province focused test completed in {total_time:.1f}s")
        print(f"   4+ province hierarchical wins: {cross_province_analysis.get('hierarchical_wins_4plus', 0)}")
        print(f"   Win rate: {cross_province_analysis.get('hierarchical_win_rate_4plus', 0):.1f}%")
        
        return results

    def _analyze_cross_province_traffic(self, traffic_logs):
        """Analyze cross-province patterns in traffic logs."""
        stats = {
            'total_events': len(traffic_logs),
            'single_province': 0,
            'cross_province_2': 0,
            'cross_province_3': 0,
            'cross_province_4plus': 0,
            'cross_province_4plus_percentage': 0,
            'avg_properties_per_event': 0,
            'avg_provinces_per_event': 0
        }
        
        total_properties = 0
        total_provinces = 0
        
        for event in traffic_logs:
            provinces = set()
            for prop_id in event:
                if '.' in prop_id:
                    provinces.add(prop_id.split('.')[0])
            
            province_count = len(provinces)
            total_properties += len(event)
            total_provinces += province_count
            
            if province_count == 1:
                stats['single_province'] += 1
            elif province_count == 2:
                stats['cross_province_2'] += 1
            elif province_count == 3:
                stats['cross_province_3'] += 1
            else:
                stats['cross_province_4plus'] += 1
        
        if stats['total_events'] > 0:
            stats['cross_province_4plus_percentage'] = (stats['cross_province_4plus'] / stats['total_events']) * 100
            stats['avg_properties_per_event'] = total_properties / stats['total_events']
            stats['avg_provinces_per_event'] = total_provinces / stats['total_events']
        
        return stats

    def _build_cross_province_tree_systems(self, documents, traffic_logs):
        """Build tree systems optimized for cross-province testing."""
        print("Building Hierarchical System...")
        hierarchical_start = time.time()
        jurisdiction_manager = JurisdictionTreeManager(documents, traffic_logs)
        jurisdiction_root = jurisdiction_manager.build_all_trees()
        hierarchical_build_time = time.time() - hierarchical_start
        
        # Update smart contract if available
        if hasattr(self, 'hierarchical_contract') and self.hierarchical_contract:
            try:
                root_bytes = bytes.fromhex(jurisdiction_root[2:] if jurisdiction_root.startswith('0x') else jurisdiction_root)
                accounts = self.web3.eth.accounts
                tx_hash = self.hierarchical_contract.functions.updateJurisdictionRoot(root_bytes).transact({'from': accounts[0]})
                self.web3.eth.wait_for_transaction_receipt(tx_hash)
                print(f"✅ Jurisdiction root updated in smart contract")
            except Exception as e:
                print(f"⚠️  Failed to update jurisdiction root: {e}")
        
        print("Building Traditional Multiproof System...")
        traditional_start = time.time()
        traditional_multiproof_builder = TraditionalMerkleTreeBuilder(documents)
        traditional_root = traditional_multiproof_builder.build()
        traditional_build_time = time.time() - traditional_start
        
        return {
            'hierarchical': {
                'manager': jurisdiction_manager,
                'root': jurisdiction_root,
                'build_time': hierarchical_build_time,
                'type': 'Hierarchical with Pairs-first Huffman'
            },
            'traditional_multiproof': {
                'builder': traditional_multiproof_builder,
                'root': traditional_root,
                'build_time': traditional_build_time,
                'type': 'Traditional Multiproof'
            }
        }

    def _run_cross_province_verification_tests(self, tree_systems, traffic_logs):
        """Run verification tests focused on cross-province scenarios."""
        results = []
        
        # Filter for 4+ province events (our main focus)
        cross_province_4plus_events = []
        other_events = []
        
        for i, event in enumerate(traffic_logs):
            provinces = set(prop_id.split('.')[0] for prop_id in event if '.' in prop_id)
            if len(provinces) >= 4:
                cross_province_4plus_events.append((i, event))
            else:
                other_events.append((i, event))
        
        print(f"Testing {len(cross_province_4plus_events)} events with 4+ provinces...")
        print(f"Testing {min(50, len(other_events))} other events for comparison...")
        
        # Test all 4+ province events
        for event_idx, event in cross_province_4plus_events:
            for approach_name, system in tree_systems.items():
                try:
                    result = self._test_cross_province_verification_event(
                        approach_name, system, event, event_idx, True  # True = is 4+ province event
                    )
                    results.append(result)
                except Exception as e:
                    print(f"    Error testing {approach_name} on event {event_idx}: {e}")
                    results.append({
                        'approach': approach_name,
                        'event': event_idx,
                        'is_4plus_province': True,
                        'error': str(e)
                    })
        
        # Test sample of other events for comparison
        sample_other_events = random.sample(other_events, min(50, len(other_events)))
        for event_idx, event in sample_other_events:
            for approach_name, system in tree_systems.items():
                try:
                    result = self._test_cross_province_verification_event(
                        approach_name, system, event, event_idx, False  # False = not 4+ province event
                    )
                    results.append(result)
                except Exception as e:
                    results.append({
                        'approach': approach_name,
                        'event': event_idx,
                        'is_4plus_province': False,
                        'error': str(e)
                    })
        
        return results

    def _test_cross_province_verification_event(self, approach_name, system, event, event_idx, is_4plus_province):
        """Test a single cross-province verification event."""
        start_time = time.time()
        
        # Count provinces and properties
        provinces = set(prop_id.split('.')[0] for prop_id in event if '.' in prop_id)
        province_count = len(provinces)
        property_count = len(event)
        
        if approach_name == 'hierarchical':
            # Hierarchical approach
            verification_request = self._convert_event_to_verification_request(event)
            proof_package = system['manager'].verify_cross_province_batch(verification_request)
            
            # Verify locally
            is_valid, reason = system['manager'].verify_proof_package_locally(proof_package)
            
            # Calculate proof size
            proof_size = self._calculate_hierarchical_proof_size(proof_package)
            
            # Estimate/execute gas
            estimated_gas = None
            actual_gas_used = None
            if self.hierarchical_contract and is_valid:
                try:
                    estimated_gas, actual_gas_used = self._estimate_hierarchical_gas(proof_package)
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'event': event_idx,
                'is_4plus_province': is_4plus_province,
                'properties_count': property_count,
                'provinces_count': province_count,
                'provinces_list': list(provinces),
                'verification_time': verification_time,
                'proof_size_bytes': proof_size,
                'estimated_gas': estimated_gas,
                'actual_gas_used': actual_gas_used,
                'local_verification_passed': is_valid,
                'reason': reason
            }
        
        elif approach_name == 'traditional_multiproof':
            # Traditional multiproof approach
            all_doc_hashes = []
            for prop_id in event:
                for doc in system['builder'].all_documents:
                    if doc.full_id == prop_id:
                        all_doc_hashes.append(doc.hash_hex)
            
            all_doc_hashes = list(dict.fromkeys(all_doc_hashes))  # Deduplicate
            
            if not all_doc_hashes:
                return {
                    'approach': approach_name,
                    'event': event_idx,
                    'is_4plus_province': is_4plus_province,
                    'error': 'No documents found for event'
                }
            
            # Generate multiproof
            proof, flags = system['builder'].generate_proof_for_documents(all_doc_hashes)
            proof_size = len(proof) * 32 + len(flags) + len(all_doc_hashes) * 32
            
            # Estimate/execute gas
            estimated_gas = None
            actual_gas_used = None
            if self.traditional_contract:
                try:
                    proof_bytes = [bytes.fromhex(p) for p in proof]
                    leaves_sorted = sorted(all_doc_hashes)
                    leaves_bytes = [bytes.fromhex(l) for l in leaves_sorted]
                    
                    if self.force_onchain_verification:
                        estimated_gas = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).estimate_gas()
                        
                        tx_hash = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).transact()
                        
                        receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
                        actual_gas_used = receipt.gasUsed
                    else:
                        estimated_gas = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).estimate_gas()
                        
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'event': event_idx,
                'is_4plus_province': is_4plus_province,
                'properties_count': property_count,
                'provinces_count': province_count,
                'provinces_list': list(provinces),
                'verification_time': verification_time,
                'proof_size_bytes': proof_size,
                'estimated_gas': estimated_gas,
                'actual_gas_used': actual_gas_used,
                'local_verification_passed': True
            }

    def _analyze_cross_province_performance(self, verification_results):
        """Analyze performance specifically for cross-province scenarios."""
        # Separate 4+ province events from others
        results_4plus = [r for r in verification_results if r.get('is_4plus_province', False) and 'error' not in r]
        results_other = [r for r in verification_results if not r.get('is_4plus_province', False) and 'error' not in r]
        
        # Group by approach
        hierarchical_4plus = [r for r in results_4plus if r['approach'] == 'hierarchical']
        traditional_4plus = [r for r in results_4plus if r['approach'] == 'traditional_multiproof']
        
        analysis = {
            'total_4plus_events_tested': len(results_4plus) // 2,  # Divide by 2 since we test both approaches
            'total_other_events_tested': len(results_other) // 2,
            'hierarchical_wins_4plus': 0,
            'traditional_wins_4plus': 0,
            'hierarchical_win_rate_4plus': 0,
            'avg_gas_savings_4plus_when_hierarchical_wins': 0,
            'best_hierarchical_cases_4plus': [],
            'performance_by_province_count': {}
        }
        
        # Compare gas costs for 4+ province events
        hierarchical_wins = []
        traditional_wins = []
        
        # Match hierarchical and traditional results for the same events
        for h_result in hierarchical_4plus:
            # Find corresponding traditional result
            t_result = next((r for r in traditional_4plus if r['event'] == h_result['event']), None)
            
            if t_result and 'estimated_gas' in h_result and 'estimated_gas' in t_result:
                if isinstance(h_result['estimated_gas'], int) and isinstance(t_result['estimated_gas'], int):
                    h_gas = h_result['estimated_gas']
                    t_gas = t_result['estimated_gas']
                    
                    if h_gas < t_gas:
                        savings = ((t_gas - h_gas) / t_gas) * 100
                        analysis['hierarchical_wins_4plus'] += 1
                        hierarchical_wins.append(savings)
                        
                        analysis['best_hierarchical_cases_4plus'].append({
                            'event': h_result['event'],
                            'provinces_count': h_result['provinces_count'],
                            'properties_count': h_result['properties_count'],
                            'gas_savings_percent': savings,
                            'hierarchical_gas': h_gas,
                            'traditional_gas': t_gas,
                            'provinces': h_result.get('provinces_list', [])
                        })
                    else:
                        analysis['traditional_wins_4plus'] += 1
                        traditional_wins.append(((h_gas - t_gas) / h_gas) * 100)
        
        # Calculate win rate and average savings
        total_comparisons = analysis['hierarchical_wins_4plus'] + analysis['traditional_wins_4plus']
        if total_comparisons > 0:
            analysis['hierarchical_win_rate_4plus'] = (analysis['hierarchical_wins_4plus'] / total_comparisons) * 100
        
        if hierarchical_wins:
            analysis['avg_gas_savings_4plus_when_hierarchical_wins'] = sum(hierarchical_wins) / len(hierarchical_wins)
        
        # Sort best cases by savings
        analysis['best_hierarchical_cases_4plus'].sort(key=lambda x: x['gas_savings_percent'], reverse=True)
        analysis['best_hierarchical_cases_4plus'] = analysis['best_hierarchical_cases_4plus'][:10]  # Top 10
        
        # Analyze by province count
        province_counts = defaultdict(lambda: {'hierarchical_wins': 0, 'traditional_wins': 0, 'savings': []})
        
        for case in analysis['best_hierarchical_cases_4plus']:
            prov_count = case['provinces_count']
            province_counts[prov_count]['hierarchical_wins'] += 1
            province_counts[prov_count]['savings'].append(case['gas_savings_percent'])
        
        for prov_count, data in province_counts.items():
            analysis['performance_by_province_count'][prov_count] = {
                'hierarchical_wins': data['hierarchical_wins'],
                'avg_savings': sum(data['savings']) / len(data['savings']) if data['savings'] else 0
            }
        
        return analysis

def main():
    """Main execution function for multi-day verification testing."""
    print("=== MULTI-DAY VERIFICATION TEST SUITE ===")
    
    # Setup Web3 connection
    try:
        web3 = Web3(Web3.HTTPProvider('http://127.0.0.1:8545'))
        if web3.is_connected():
            web3.eth.default_account = web3.eth.accounts[0]
            print("✅ Connected to Hardhat for gas analysis")
        else:
            print("⚠️  No Hardhat connection - running without gas analysis")
            web3 = None
    except Exception as e:
        print(f"⚠️  Web3 connection failed: {e}")
        web3 = None
    
    # Create test suite
    test_suite = MultiDayVerificationSuite(web3)
    
    # Run comprehensive test
    report = test_suite.run_comprehensive_multi_day_test(
        document_count=2000,
        num_days=5,
        base_events_per_day=200
    )
    
    # Print key results
    if 'optimization_analysis' in report and 'optimization_ratios' in report['optimization_analysis']:
        ratios = report['optimization_analysis']['optimization_ratios']
        print(f"\n🎯 OPTIMIZATION RESULTS:")
        print(f"  Proof Size Reduction: {ratios['proof_size_reduction']:.1f}%")
        print(f"  Gas Cost Reduction (Estimated): {ratios['gas_reduction_estimated']:.1f}%")
        print(f"  Gas Cost Reduction (Actual): {ratios['gas_reduction_actual']:.1f}%")
        print(f"  Time Improvement: {ratios['time_improvement']:.1f}%")
        
    # Print estimation accuracy analysis
    if 'optimization_analysis' in report and 'estimation_accuracy' in report['optimization_analysis']:
        accuracy = report['optimization_analysis']['estimation_accuracy']
        print(f"\n📊 ESTIMATION vs ACTUAL ANALYSIS:")
        
        if 'comparison' in accuracy:
            comp = accuracy['comparison']
            print(f"  Estimated Gas Reduction: {comp['estimated_gas_reduction']:.1f}%")
            print(f"  Actual Gas Reduction: {comp['actual_gas_reduction']:.1f}%")
            print(f"  Difference: {comp['reduction_difference']:.1f} percentage points")
            print(f"  Impact: {'Estimation was pessimistic' if comp['accuracy_impact'] == 'estimation_worse' else 'Estimation was optimistic'}")
        
        if 'hierarchical' in accuracy:
            hier = accuracy['hierarchical']
            print(f"  Hierarchical Estimation Error: {hier['estimation_error_percent']:.1f}% ({hier['estimation_direction']})")
            
        if 'traditional' in accuracy:
            trad = accuracy['traditional']
            print(f"  Traditional Estimation Error: {trad['estimation_error_percent']:.1f}% ({trad['estimation_direction']})")
    
    print(f"\n✅ Multi-day verification test completed successfully!")

class MultiDayVerificationSuiteExtensions:
    """Extension methods for MultiDayVerificationSuite to handle cross-province focused testing."""
    
    def run_cross_province_focused_test(self, documents, properties_by_province, traffic_logs, force_onchain_verification=False):
        """
        Run verification test focused on cross-province scenarios.
        
        Args:
            documents: Generated documents
            properties_by_province: Properties organized by province
            traffic_logs: Pre-generated traffic logs (should be 80% 4+ cross-province)
            force_onchain_verification: Whether to execute on-chain transactions
            
        Returns:
            Cross-province focused test results
        """
        print(f"{'='*60}")
        print(f"CROSS-PROVINCE FOCUSED VERIFICATION TEST")
        print(f"{'='*60}")
        
        self.force_onchain_verification = force_onchain_verification
        
        start_time = time.time()
        
        # Analyze traffic patterns first
        cross_province_stats = self._analyze_cross_province_traffic(traffic_logs)
        print(f"Traffic Analysis:")
        print(f"  Total events: {cross_province_stats['total_events']}")
        print(f"  4+ province events: {cross_province_stats['cross_province_4plus']} ({cross_province_stats['cross_province_4plus_percentage']:.1f}%)")
        
        # Build tree systems
        print(f"\nBuilding tree systems...")
        tree_systems = self._build_cross_province_tree_systems(documents, traffic_logs)
        
        # Run verification tests focused on 4+ province scenarios
        print(f"\nRunning cross-province verification tests...")
        verification_results = self._run_cross_province_verification_tests(tree_systems, traffic_logs)
        
        # Analyze results with focus on 4+ province scenarios
        print(f"\nAnalyzing cross-province performance...")
        cross_province_analysis = self._analyze_cross_province_performance(verification_results)
        
        total_time = time.time() - start_time
        
        results = {
            'test_metadata': {
                'test_type': 'cross_province_focused',
                'total_duration_seconds': total_time,
                'document_count': len(documents),
                'traffic_events': len(traffic_logs),
                'timestamp': datetime.now().isoformat(),
                'force_onchain_verification': force_onchain_verification
            },
            'cross_province_traffic_stats': cross_province_stats,
            'tree_systems': {
                name: {
                    'type': system['type'],
                    'build_time': system['build_time'],
                    'root': system['root'][:16] + '...' if system['root'] else None
                }
                for name, system in tree_systems.items()
            },
            'verification_results': verification_results,
            'cross_province_analysis': cross_province_analysis,
            'performance_summary': {
                'hierarchical_wins_4plus_provinces': cross_province_analysis.get('hierarchical_wins_4plus', 0),
                'traditional_wins_4plus_provinces': cross_province_analysis.get('traditional_wins_4plus', 0),
                'hierarchical_win_rate_4plus': cross_province_analysis.get('hierarchical_win_rate_4plus', 0)
            }
        }
        
        print(f"\n✅ Cross-province focused test completed in {total_time:.1f}s")
        print(f"   4+ province hierarchical wins: {cross_province_analysis.get('hierarchical_wins_4plus', 0)}")
        print(f"   Win rate: {cross_province_analysis.get('hierarchical_win_rate_4plus', 0):.1f}%")
        
        return results

    def _analyze_cross_province_traffic(self, traffic_logs):
        """Analyze cross-province patterns in traffic logs."""
        stats = {
            'total_events': len(traffic_logs),
            'single_province': 0,
            'cross_province_2': 0,
            'cross_province_3': 0,
            'cross_province_4plus': 0,
            'cross_province_4plus_percentage': 0,
            'avg_properties_per_event': 0,
            'avg_provinces_per_event': 0
        }
        
        total_properties = 0
        total_provinces = 0
        
        for event in traffic_logs:
            provinces = set()
            for prop_id in event:
                if '.' in prop_id:
                    provinces.add(prop_id.split('.')[0])
            
            province_count = len(provinces)
            total_properties += len(event)
            total_provinces += province_count
            
            if province_count == 1:
                stats['single_province'] += 1
            elif province_count == 2:
                stats['cross_province_2'] += 1
            elif province_count == 3:
                stats['cross_province_3'] += 1
            else:
                stats['cross_province_4plus'] += 1
        
        if stats['total_events'] > 0:
            stats['cross_province_4plus_percentage'] = (stats['cross_province_4plus'] / stats['total_events']) * 100
            stats['avg_properties_per_event'] = total_properties / stats['total_events']
            stats['avg_provinces_per_event'] = total_provinces / stats['total_events']
        
        return stats

    def _build_cross_province_tree_systems(self, documents, traffic_logs):
        """Build tree systems optimized for cross-province testing."""
        print("Building Hierarchical System...")
        hierarchical_start = time.time()
        jurisdiction_manager = JurisdictionTreeManager(documents, traffic_logs)
        jurisdiction_root = jurisdiction_manager.build_all_trees()
        hierarchical_build_time = time.time() - hierarchical_start
        
        # Update smart contract if available
        if hasattr(self, 'hierarchical_contract') and self.hierarchical_contract:
            try:
                root_bytes = bytes.fromhex(jurisdiction_root[2:] if jurisdiction_root.startswith('0x') else jurisdiction_root)
                accounts = self.web3.eth.accounts
                tx_hash = self.hierarchical_contract.functions.updateJurisdictionRoot(root_bytes).transact({'from': accounts[0]})
                self.web3.eth.wait_for_transaction_receipt(tx_hash)
                print(f"✅ Jurisdiction root updated in smart contract")
            except Exception as e:
                print(f"⚠️  Failed to update jurisdiction root: {e}")
        
        print("Building Traditional Multiproof System...")
        traditional_start = time.time()
        traditional_multiproof_builder = TraditionalMerkleTreeBuilder(documents)
        traditional_root = traditional_multiproof_builder.build()
        traditional_build_time = time.time() - traditional_start
        
        return {
            'hierarchical': {
                'manager': jurisdiction_manager,
                'root': jurisdiction_root,
                'build_time': hierarchical_build_time,
                'type': 'Hierarchical with Pairs-first Huffman'
            },
            'traditional_multiproof': {
                'builder': traditional_multiproof_builder,
                'root': traditional_root,
                'build_time': traditional_build_time,
                'type': 'Traditional Multiproof'
            }
        }

    def _run_cross_province_verification_tests(self, tree_systems, traffic_logs):
        """Run verification tests focused on cross-province scenarios."""
        results = []
        
        # Filter for 4+ province events (our main focus)
        cross_province_4plus_events = []
        other_events = []
        
        for i, event in enumerate(traffic_logs):
            provinces = set(prop_id.split('.')[0] for prop_id in event if '.' in prop_id)
            if len(provinces) >= 4:
                cross_province_4plus_events.append((i, event))
            else:
                other_events.append((i, event))
        
        print(f"Testing {len(cross_province_4plus_events)} events with 4+ provinces...")
        print(f"Testing {min(50, len(other_events))} other events for comparison...")
        
        # Test all 4+ province events
        for event_idx, event in cross_province_4plus_events:
            for approach_name, system in tree_systems.items():
                try:
                    result = self._test_cross_province_verification_event(
                        approach_name, system, event, event_idx, True  # True = is 4+ province event
                    )
                    results.append(result)
                except Exception as e:
                    print(f"    Error testing {approach_name} on event {event_idx}: {e}")
                    results.append({
                        'approach': approach_name,
                        'event': event_idx,
                        'is_4plus_province': True,
                        'error': str(e)
                    })
        
        # Test sample of other events for comparison
        sample_other_events = random.sample(other_events, min(50, len(other_events)))
        for event_idx, event in sample_other_events:
            for approach_name, system in tree_systems.items():
                try:
                    result = self._test_cross_province_verification_event(
                        approach_name, system, event, event_idx, False  # False = not 4+ province event
                    )
                    results.append(result)
                except Exception as e:
                    results.append({
                        'approach': approach_name,
                        'event': event_idx,
                        'is_4plus_province': False,
                        'error': str(e)
                    })
        
        return results

    def _test_cross_province_verification_event(self, approach_name, system, event, event_idx, is_4plus_province):
        """Test a single cross-province verification event."""
        start_time = time.time()
        
        # Count provinces and properties
        provinces = set(prop_id.split('.')[0] for prop_id in event if '.' in prop_id)
        province_count = len(provinces)
        property_count = len(event)
        
        if approach_name == 'hierarchical':
            # Hierarchical approach
            verification_request = self._convert_event_to_verification_request(event)
            proof_package = system['manager'].verify_cross_province_batch(verification_request)
            
            # Verify locally
            is_valid, reason = system['manager'].verify_proof_package_locally(proof_package)
            
            # Calculate proof size
            proof_size = self._calculate_hierarchical_proof_size(proof_package)
            
            # Estimate/execute gas
            estimated_gas = None
            actual_gas_used = None
            if self.hierarchical_contract and is_valid:
                try:
                    estimated_gas, actual_gas_used = self._estimate_hierarchical_gas(proof_package)
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'event': event_idx,
                'is_4plus_province': is_4plus_province,
                'properties_count': property_count,
                'provinces_count': province_count,
                'provinces_list': list(provinces),
                'verification_time': verification_time,
                'proof_size_bytes': proof_size,
                'estimated_gas': estimated_gas,
                'actual_gas_used': actual_gas_used,
                'local_verification_passed': is_valid,
                'reason': reason
            }
        
        elif approach_name == 'traditional_multiproof':
            # Traditional multiproof approach
            all_doc_hashes = []
            for prop_id in event:
                for doc in system['builder'].all_documents:
                    if doc.full_id == prop_id:
                        all_doc_hashes.append(doc.hash_hex)
            
            all_doc_hashes = list(dict.fromkeys(all_doc_hashes))  # Deduplicate
            
            if not all_doc_hashes:
                return {
                    'approach': approach_name,
                    'event': event_idx,
                    'is_4plus_province': is_4plus_province,
                    'error': 'No documents found for event'
                }
            
            # Generate multiproof
            proof, flags = system['builder'].generate_proof_for_documents(all_doc_hashes)
            proof_size = len(proof) * 32 + len(flags) + len(all_doc_hashes) * 32
            
            # Estimate/execute gas
            estimated_gas = None
            actual_gas_used = None
            if self.traditional_contract:
                try:
                    proof_bytes = [bytes.fromhex(p) for p in proof]
                    leaves_sorted = sorted(all_doc_hashes)
                    leaves_bytes = [bytes.fromhex(l) for l in leaves_sorted]
                    
                    if self.force_onchain_verification:
                        estimated_gas = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).estimate_gas()
                        
                        tx_hash = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).transact()
                        
                        receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
                        actual_gas_used = receipt.gasUsed
                    else:
                        estimated_gas = self.traditional_contract.functions.verifyBatch(
                            proof_bytes, flags, leaves_bytes
                        ).estimate_gas()
                        
                except Exception as e:
                    estimated_gas = f"Error: {e}"
            
            verification_time = time.time() - start_time
            
            return {
                'approach': approach_name,
                'event': event_idx,
                'is_4plus_province': is_4plus_province,
                'properties_count': property_count,
                'provinces_count': province_count,
                'provinces_list': list(provinces),
                'verification_time': verification_time,
                'proof_size_bytes': proof_size,
                'estimated_gas': estimated_gas,
                'actual_gas_used': actual_gas_used,
                'local_verification_passed': True
            }

    def _analyze_cross_province_performance(self, verification_results):
        """Analyze performance specifically for cross-province scenarios."""
        # Separate 4+ province events from others
        results_4plus = [r for r in verification_results if r.get('is_4plus_province', False) and 'error' not in r]
        results_other = [r for r in verification_results if not r.get('is_4plus_province', False) and 'error' not in r]
        
        # Group by approach
        hierarchical_4plus = [r for r in results_4plus if r['approach'] == 'hierarchical']
        traditional_4plus = [r for r in results_4plus if r['approach'] == 'traditional_multiproof']
        
        analysis = {
            'total_4plus_events_tested': len(results_4plus) // 2,  # Divide by 2 since we test both approaches
            'total_other_events_tested': len(results_other) // 2,
            'hierarchical_wins_4plus': 0,
            'traditional_wins_4plus': 0,
            'hierarchical_win_rate_4plus': 0,
            'avg_gas_savings_4plus_when_hierarchical_wins': 0,
            'best_hierarchical_cases_4plus': [],
            'performance_by_province_count': {}
        }
        
        # Compare gas costs for 4+ province events
        hierarchical_wins = []
        traditional_wins = []
        
        # Match hierarchical and traditional results for the same events
        for h_result in hierarchical_4plus:
            # Find corresponding traditional result
            t_result = next((r for r in traditional_4plus if r['event'] == h_result['event']), None)
            
            if t_result and 'estimated_gas' in h_result and 'estimated_gas' in t_result:
                if isinstance(h_result['estimated_gas'], int) and isinstance(t_result['estimated_gas'], int):
                    h_gas = h_result['estimated_gas']
                    t_gas = t_result['estimated_gas']
                    
                    if h_gas < t_gas:
                        savings = ((t_gas - h_gas) / t_gas) * 100
                        analysis['hierarchical_wins_4plus'] += 1
                        hierarchical_wins.append(savings)
                        
                        analysis['best_hierarchical_cases_4plus'].append({
                            'event': h_result['event'],
                            'provinces_count': h_result['provinces_count'],
                            'properties_count': h_result['properties_count'],
                            'gas_savings_percent': savings,
                            'hierarchical_gas': h_gas,
                            'traditional_gas': t_gas,
                            'provinces': h_result.get('provinces_list', [])
                        })
                    else:
                        analysis['traditional_wins_4plus'] += 1
                        traditional_wins.append(((h_gas - t_gas) / h_gas) * 100)
        
        # Calculate win rate and average savings
        total_comparisons = analysis['hierarchical_wins_4plus'] + analysis['traditional_wins_4plus']
        if total_comparisons > 0:
            analysis['hierarchical_win_rate_4plus'] = (analysis['hierarchical_wins_4plus'] / total_comparisons) * 100
        
        if hierarchical_wins:
            analysis['avg_gas_savings_4plus_when_hierarchical_wins'] = sum(hierarchical_wins) / len(hierarchical_wins)
        
        # Sort best cases by savings
        analysis['best_hierarchical_cases_4plus'].sort(key=lambda x: x['gas_savings_percent'], reverse=True)
        analysis['best_hierarchical_cases_4plus'] = analysis['best_hierarchical_cases_4plus'][:10]  # Top 10
        
        # Analyze by province count
        province_counts = defaultdict(lambda: {'hierarchical_wins': 0, 'traditional_wins': 0, 'savings': []})
        
        for case in analysis['best_hierarchical_cases_4plus']:
            prov_count = case['provinces_count']
            province_counts[prov_count]['hierarchical_wins'] += 1
            province_counts[prov_count]['savings'].append(case['gas_savings_percent'])
        
        for prov_count, data in province_counts.items():
            analysis['performance_by_province_count'][prov_count] = {
                'hierarchical_wins': data['hierarchical_wins'],
                'avg_savings': sum(data['savings']) / len(data['savings']) if data['savings'] else 0
            }
        
        return analysis

if __name__ == "__main__":
    main()
